{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape the DOH daily totals page\n",
    "Cut and paste into the totals.csv when it looks okay.\n",
    "\n",
    "Probably could import totals.csv and then update if the new date is later than the old. Possibly with a loop until that happens. But, still have to read the footnotes to get new cases. So, doesn't seem worth it for now. \n",
    "\n",
    "Longer term the CSVDownload.csv on the dashboard might be a better way to get daily cases. <s>However, that is only available via the Tableau button on the charts right now.</s>\n",
    "    \n",
    "See tests_to_freq in the doh_data folder for automatic downloading of the CSV data.    \n",
    "\n",
    "The problem with that data is that it doesn't include \"Outside Hawaii\". Maybe that's better since the official benchmarks don't either?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time           #in case we want to hit the server in a loop and need a delay\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://health.hawaii.gov/coronavirusdisease2019/'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 14233* (78 new)\n",
      "Hawai’i County: 1091\n",
      "Honolulu County: 12617\n",
      "Kaua’i County: 60\n",
      "Maui County: 417†\n",
      "Pending: 0\n",
      "Residents diagnosed outside of Hawai‘i: 48\n",
      "Required Hospitalization: 1033‡\n",
      "Hawaii deaths: 203\n",
      "Released from Isolation: 11188§\n",
      "Cumulative totals as of 12:00pm, October 21, 2020\n"
     ]
    }
   ],
   "source": [
    "for t in soup('dd'):\n",
    "    print(t.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10/21/2020',\n",
       " '14233',\n",
       " '1091',\n",
       " '12617',\n",
       " '60',\n",
       " '417',\n",
       " '0',\n",
       " '48',\n",
       " '1033',\n",
       " '203',\n",
       " '11188']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = []\n",
    "vals.append(parse(soup.find(string=re.compile('Cumulative totals as of'))[23:]).strftime('%m/%d/%Y'))\n",
    "for t in soup('dd'):\n",
    "    for d in t(class_='value'):\n",
    "        vals.append(re.findall(r'\\b\\d+\\b',t.get_text())[0])\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/21/2020,14233,12617,1091,417,60,48\n"
     ]
    }
   ],
   "source": [
    "print(vals[0]+','+vals[1]+','+vals[3]+','+vals[2]+','+vals[5]+','+vals[4]+','+vals[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
